---
title: "Homework1_Q3"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regression vs KNN

```{r, include=FALSE}
library(tidyverse)
library(FNN)
library(mosaic)
library(ggplot2)
```

Extract two trims(350 and 65 AMG) from all trim levels.
```{r, include=FALSE}
# read data 
sclass <- read.csv("~/Documents/GitHub/ECO395M/data/sclass.csv")

# two category
sclass350 = subset(sclass, trim == '350')

sclass65AMG = subset(sclass, trim == '65 AMG')

```

1.Split the data into training and testing set.

```{r,echo=FALSE}
# training and testing data
N1 = nrow(sclass350)
N1_train = floor(0.8*N1)
N1_test = N1 - N1_train

N2 = nrow(sclass65AMG)
N2_train = floor(0.8*N2)
N2_test = N2 - N2_train
# sample a set of data in train data
train_1 = sample.int(N1, N1_train, replace=FALSE)
train_2 = sample.int(N2, N2_train, replace=FALSE)

```

```{r}
# define training and testing data
D1_train = sclass350[train_1,]
D1_test = sclass350[-train_1,]

D2_train = sclass65AMG[train_2,]
D2_test = sclass65AMG[-train_2,]

D1_test = arrange(D1_test, mileage)
D2_test = arrange(D2_test, mileage)

```
```{r, include=FALSE}
# define name tag
X1_train = select(D1_train, mileage)
y1_train = select(D1_train, price)
X1_test = select(D1_test, mileage)
y1_test = select(D1_test, price)

X2_train = select(D2_train, mileage)
y2_train = select(D2_train, price)
X2_test = select(D2_test, mileage)
y2_test = select(D2_test, price)

```
2.Run K-nearest-neighbors, for many different values of K, starting at K=3. For each value of K, fit the model to the training set and make predictions on your test set.

3.Calculate the out-of-sample root mean-squared error (RMSE) for each value of K.
```{r, include=FALSE}
# define rmse function
rmse = function(y, ypred) {
  sqrt(mean(data.matrix((y-ypred)^2)))
}
```

```{r}
rmse1.matrix= matrix(NA,nrow = 328, ncol = 2)
for (i in 3:330) {
  knn=knn.reg(train = X1_train, test = X1_test, y= y1_train, k=i)
  ypred_knn = knn$pred
  rmse(y1_test, ypred_knn)
  rmse1.matrix[i-2,2]=rmse(y1_test, ypred_knn)
  rmse1.matrix[i-2,1]=i
}

rmse2.matrix= matrix(NA,nrow = 228, ncol = 2)
for (i in 3:230) {
  knn=knn.reg(train = X2_train, test = X2_test, y= y2_train, k=i)
  ypred_knn = knn$pred
  rmse(y1_test, ypred_knn)
  rmse2.matrix[i-2,2]=rmse(y2_test, ypred_knn)
  rmse2.matrix[i-2,1]=i
} 
```
Make plot of RMSE versus K for trim 350


```{r,echo=FALSE}
#plot rmse vesus k
plot(rmse1.matrix,type = "l",xlab = "k", ylab = "rmse", main = "350")
```
Make plot of RMSE versus K for trim 65AMG


```{r,echo=FALSE}
#plot rmse vesus k
plot(rmse1.matrix,type = "l",xlab = "k", ylab = "rmse", main = "65AMG")

```

For the optimal value of K, the plot of fitted model for trim 350
The optimal value of K is below:
```{r,include= FALSE}
k1.matrix= matrix(NA, nrow =100, ncol= 1)
k2.matrix= matrix(NA, nrow =100, ncol= 1)
# all loop
for (n in 1:100) {
  
# sample a set of data in train data
train_1 = sample.int(N1, N1_train, replace=FALSE)
train_2 = sample.int(N2, N2_train, replace=FALSE)

# define data name tag
D1_train = sclass350[train_1,]
D1_test = sclass350[-train_1,]

D2_train = sclass65AMG[train_2,]
D2_test = sclass65AMG[-train_2,]

D1_test = arrange(D1_test, mileage)
D2_test = arrange(D2_test, mileage)

X1_train = select(D1_train, mileage)
y1_train = select(D1_train, price)
X1_test = select(D1_test, mileage)
y1_test = select(D1_test, price)

X2_train = select(D2_train, mileage)
y2_train = select(D2_train, price)
X2_test = select(D2_test, mileage)
y2_test = select(D2_test, price)


# define KNN loop
rmse1.matrix= matrix(NA,nrow = 328, ncol = 1)
for (i in 3:330) {
 knn=knn.reg(train = X1_train, test = X1_test, y= y1_train, k=i)
 ypred_knn = knn$pred
 rmse(y1_test, ypred_knn)
 rmse1.matrix[i-2,1]=rmse(y1_test, ypred_knn)
}

rmse2.matrix= matrix(NA,nrow = 228, ncol = 1)
for (i in 3:230) {
  knn=knn.reg(train = X2_train, test = X2_test, y= y2_train, k=i)
  ypred_knn = knn$pred
  rmse(y1_test, ypred_knn)
  rmse2.matrix[i-2,1]=rmse(y2_test, ypred_knn)
}

# find minimum rmse
apply(rmse1.matrix, 2, min)
k1.matrix[n,1]=which.min(rmse1.matrix)+2

apply(rmse2.matrix, 2, min)
k2.matrix[n,1]=which.min(rmse2.matrix)+2

}

```
```{r,echo= FALSE}
#use mean to find minimum k1
k1=mean(k1.matrix)
k1=floor(k1)
k1

```
The corresponding RMSE is below:
```{r,echo=FALSE}
knnk1 = knn.reg(train = X1_train, test = X1_test, y = y1_train, k=k1)
ypred_knnk1 = knnk1$pred
rmse(y1_test, ypred_knnk1)
```

The plot of fitted model for trim 350


```{r,echo=FALSE}
D1_test$ypred_knnk1 = ypred_knnk1
p1_test = ggplot(data = D1_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + 
  ylim(6000, 120000)
p1_test
p1_test + geom_point(aes(x = mileage, y = ypred_knnk1), color='red')
```


For the optimal value of K, the plot of fitted model for trim 65AMG
The optimal value of K is below:
```{r,echo=FALSE}
k2=mean(k2.matrix)
k2=floor(k2)
k2
```
The corresponding RMSE is below:

```{r,echo=FALSE}
knnk2 = knn.reg(train = X2_train, test = X2_test, y = y2_train, k=k2)
ypred_knnk2 = knnk2$pred
rmse(y2_test, ypred_knnk2)

```

The plot of fitted model for trim 65AMG


```{r,echo=FALSE}
D2_test$ypred_knnk2 = ypred_knnk2
p2_test = ggplot(data = D2_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + 
  ylim(18000, 250000)
p2_test
p2_test + geom_point(aes(x = mileage, y = ypred_knnk2), color='red')

```



##Which trim yields a larger optimal value of K? Why do you think this is?
Trim 350 yeilds larger optimal value of K. Because the sample size for trim 350 is larger than trim 65AMG. Then I guess the larger the sample size is, the larger the optimal K will be.



